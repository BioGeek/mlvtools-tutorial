# POC versioning Machine Learning pipeline

This repository is a tutorial to explain a process of **versioning** and 
**automation** of a **Machine Learning Project** using the combination of
 the following tools:
 - [Data Science Version Control](https://github.com/iterative/dvc) or DVC
 - [MLflow tracking](https://github.com/mlflow/mlflow)
 - [MLVtools](https://github.com/peopledoc/ml-versioning-tools)
 
Use cases are based on a text classification task on 20newsgroup dataset. A *dummy* tutorial is also available
to show tools mechanisms.

**Requirements:**
- virtualenv or condaenv
- make

## How To

To complete this tutorial clone this repository:

    git clone https://github.com/peopledoc/mlv-tools-tutorial
    
Activate your **Python 3** virtual environment.

Install requirements:

    make develop
    
All other steps are explain in each use cases.

## Keywords

**DVC meta files**: DVC metadata files generated by DVC `add` and `run` command. Extension: **.dvc**


## Dummy Tutorial Use Case

The aim of this tutorial is to show how **MLV-tools**, **DVC** and **MLflow tracking** work on a trivial case.
See [dummy tutorial](./tutorial/dummy.md). 

## Realistic Tutorial Use Cases

For a more realistic use case, we consider a Natural Language Processing pipeline, based on the well-known dataset 20-newsgroups. 

The base pipeline is simplified to include the following steps:
 1. Split the data between train and test sets;
 2. Tokenize (split into words) the raw text input;
 3. Classify the cleaned input with FastText;
 4. Evaluate the model.
 
In addition, use case 4 showcases hyperparameter tuning with a scikit-learn classifier.

The use cases considered are the following:
- Reproduce a pipeline / experience on new data ([Use Case 1: Build and Reproduce a Pipeline](./tutorial/use_case1.md))
- Versioning and storage of intermediate (preprocessed) datasets; partial execution of the pipeline starting from precomputed data
  ([Use Case 2: Create a new version of a pipeline](./tutorial/use_case2.md) and [Use Case 3: Build a Pipeline from an Existing Pipeline](./tutorial/use_case3.md))
- Hyperparameter optimisation and fine-tuning (saving results, [Use Case 4: Combine Metrics](./tutorial/use_case4.md))

These use cases were chosen because we think they represent typical day-to-day work of a data scientist: being able to reproduce easily a pipeline made some time ago or by a coworker, versioning intermediate state of the data to avoid rerunning costly preprocessing steps, branching experiments to run tests with different classifiers, fine-tuning hyperparameters. 

## Standard Versioning Process

The process used in this tutorial is a way to version code, data and pipelines.
Speaking of code the reference will always be the **Jupyter notebook**. 
Speaking of input and output data the reference is the set of parameters define in each **DVC** commands.

For each **Jupyter notebook** a **Python 3** parameterizable and executable script is generated. It is the way to 
version code and be able to automatize its run.

Pipelines are composed of **DVC** steps. Those steps can be generated directly from the **Jupyter notebook** based
on parameters describe in the Docstring. (notebook -> python script -> DVC command)

For steps which reused same code part (for example the evaluation step run once on train data then on test data) it is
not useful to convert again the **Jupyter notebook** to a **Python 3** script then to a **DVC** command again. You just 
need to duplicate the corresponding **DVC** command file and then to edit inputs, outputs and meta file name. 


Each time a **DVC** step is run a **DVC meta file** (`[normalize_notebook_name].dvc`) is created. This meta file represent 
a pipeline step, it is used to track outputs and dependencies. You can use **dvc repro [DVC meta file]** to re-run
all needed pipeline steps to achieve the one corresponding to this meta file.

For each step in the tutorial the process remain the same.
   
   1. Write a **Jupyter notebook** which correspond to a pipeline step. (See **Jupyter notebook** syntax section in 
   [MLVtools documentation](https://github.com/peopledoc/ml-versioning-tools))
   2. Test your **Jupyter notebook**.
   3. Add it under git.
   4. Convert the **Jupyter notebook** into a parameterized and executable **Python 3** script using *ipynb_to_python*.
       
            ipynb_to_python -n ./pipeline/notebooks/[notebook_name] -o ./pipeline/steps/[python_script_name]
            
   5. Ensure **Python 3** executable and configurable script is well created into `./pipeline/steps/[python_script_name]`.
            
            ./pipeline/steps/[python_script_name] -h
    
   6. Create a **DVC** commands to run the **Python 3** script using **DVC**.
   
            gen_dvc -i ./pipeline/steps/[python_script_name] \
                        --out-dvc-cmd ./scripts/cmd/[dvc_cmd_name] 

   7. Ensure **DVC** command is well created.
   8. Add generated command and **Python 3** script under git.
   9. Add step inputs under **DVC**.
   10. Run **DVC** command `./scripts/cmd/[dvc_cmd_name]`.
   11. Check **DVC meta file** is created `./[normalize notebook _name].dvc`
   12. Add **DVC meta file** under git/
   

## Tutorial

The realistic tutorial entry point is the [tutorial setup](./tutorial/setup.md) step.

The **dummy** tutorial entry point is [here](./tutorial/dummy.md).

## Key Features
|Need| Feature|
|:---|:---|
| Ignore notebook cell | # No effect |
| DVC input and ouptuts | **:dvc-in**, **:dvc-out**|
| Add extra parameters | **:dvc-extra**|
| Write DVC whole command | **:dvc-cmd**|
| Convert Jupiter Notebook to Python 3 script | **ipynb_to_python**|
| Generate DVC command | **gen_dvc**|
| Create a pipeline step from a Jupiter Notebook | ipynb_to_python, gen_dvc |
| Add a pipeline step with different IO | Copy **DVC** step then edit inputs, outputs and meta file name |
| Reproduce a pipeline | **dvc repro [metafile]**|
| Reproduce a pipeline with no cache | **dvc repro -f [metafile]**|
| Reproduce a pipeline after an algo change | **dvc repro -f [metafile]** or run impacted step individually then complete the pipeline.|


It is allowed to modify or duplicate a **DVC** command to change an hyperparameter or run a same step twice with
different parameters.

It is a bad idea to modify generated **Python 3** scripts. They are generated from **Jupyter notebooks**, so changes 
should be done in them and then scripts should be re-generated.
