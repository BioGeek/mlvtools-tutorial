{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune hyperparameters using cross-validation\n",
    "\n",
    "In this notebook, we will tune hyper-parameters of a simple text classification pipeline. \n",
    "\n",
    "Starting from the raw text data, we will encode it using bag of words (*hyperparameter 1*: number of words in the vocabulary), and then train a Logisitic Regression classifier (*hyperparameter 2*: regularization parameter). We will evaluate performance using (repeated) cross-validation.\n",
    "\n",
    "Metrics from each of the run will be stored with **MLFlow tracking API**. That's the output we want to version with **DVC**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\"\"\"\n",
    ":param str input_csv_file: Path to input file\n",
    ":param List[float] C_list: List of inverse of regularisation coefficient values\n",
    ":param List[int] max_features_list: List the maximum number of features\n",
    ":param str mlflow_output: MLflow metrics directory\n",
    ":dvc-in input_csv_file: ./poc/data/data_train.csv\n",
    ":dvc-out mlflow_output : ./poc/data/cross_valid_metrics\n",
    ":dvc-extra: --C-list .1 1.0 --max-features-list 100 500 1000\n",
    "\"\"\"\n",
    "# Value of parameters for this Jupyter Notebook only\n",
    "# the notebook is in ./poc/pipeline/notebooks\n",
    "input_csv_file = \"../../data/data_train.csv\"\n",
    "C_list = [.1, 1.0]\n",
    "max_features_list = [100, 500, 1000]\n",
    "mlflow_output='../../data/cross_valid_metrics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_validate, RepeatedStratifiedKFold\n",
    "import mlflow\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(input_csv_file).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(d):\n",
    "    for metrics, values in d.items():\n",
    "        mlflow.log_metric(metrics + '_avg', values.mean())\n",
    "        mlflow.log_metric(metrics + '_std', values.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(mlflow_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for C, max_features in product(C_list, max_features_list):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param('C', C)\n",
    "        mlflow.log_param('max_features', max_features)\n",
    "        classifier = LogisticRegression(C=C,\n",
    "                                        solver='lbfgs',\n",
    "                                        multi_class='multinomial')\n",
    "        vectorizer = CountVectorizer(max_features=max_features,\n",
    "                                     stop_words='english')\n",
    "        pipeline = Pipeline([('vectorizer', vectorizer),\n",
    "                         (classifier.__repr__().split('(')[0], classifier)])\n",
    "        d = cross_validate(pipeline,\n",
    "                           X=df['data'],\n",
    "                           y=df['target'],\n",
    "                           scoring=['accuracy', 'precision_macro', 'f1_micro', 'f1_macro'],\n",
    "                           cv=RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=0))\n",
    "        log_results(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:poc_ml_versioning]",
   "language": "python",
   "name": "conda-env-poc_ml_versioning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
